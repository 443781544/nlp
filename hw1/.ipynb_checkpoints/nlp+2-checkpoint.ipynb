{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUnLBypJRAyL"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVIBs4HOedVg"
   },
   "source": [
    "没有做作业要求的文本预处理，但是好像nltk自带了预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTRwquUiRzrt"
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(open('training_data.txt').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGfeGOrFe4ef"
   },
   "source": [
    "## build n-grams\n",
    "n-gram都是字典<br/>\n",
    "bigram和trigram的key为了能够写到文件里所以加了一层str()，其实可以去掉，如果不去掉键就是一个str(tuple)，tuple是要查找的键，是一个元组,去掉之后key就是一个元组\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfzDnm7cR6Ln"
   },
   "outputs": [],
   "source": [
    "unigram = {}\n",
    "for token in tokens:\n",
    "  try:\n",
    "    unigram[token] += 1\n",
    "  except:\n",
    "    unigram[token] = 1\n",
    "\n",
    "bigram = {}\n",
    "for i in range(1,len(tokens)):\n",
    "  try:\n",
    "    #bigram[str((tokens[i],tokens[i-1]))] += 1\n",
    "    bigram[(tokens[i],tokens[i-1])] += 1\n",
    "  except:\n",
    "    #bigram[str((tokens[i],tokens[i-1]))] = 1\n",
    "    bigram[(tokens[i],tokens[i-1])] = 1\n",
    "\n",
    "trigram = {}\n",
    "for i in range(2,len(tokens)):\n",
    "  try:\n",
    "    #trigram[str((tokens[i],tokens[i-1],tokens[i-2]))] += 1\n",
    "    trigram[(tokens[i],tokens[i-1],tokens[i-2])] += 1\n",
    "  except:\n",
    "    #trigram[str((tokens[i],tokens[i-1],tokens[i-2]))] = 1\n",
    "    trigram[(tokens[i],tokens[i-1],tokens[i-2])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "mI3Anc59gOqC",
    "outputId": "00cb6fde-f5a1-4500-a7c7-3c63b2af5483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34352\n",
      "2475\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "print(unigram['a'])\n",
    "# print(bigram[str(('this','in'))])\n",
    "print(bigram[('this','in')])\n",
    "# print(trigram[str(('as', 'soon', 'as'))])\n",
    "print(trigram[('as', 'soon', 'as')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1rOTPHW1HHq"
   },
   "source": [
    "由于单纯的字典在key不存在时会报错，所以将n_gram封装为函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AnF5L-81RYn"
   },
   "outputs": [],
   "source": [
    "def uni(key):\n",
    "  try:\n",
    "    return unigram[key]\n",
    "  except:\n",
    "    return 0\n",
    "\n",
    "def bi(key):\n",
    "  try:\n",
    "    return bigram[key]\n",
    "  except:\n",
    "    return 0\n",
    "\n",
    "def tri(key):\n",
    "  try:\n",
    "    return trigram[key]\n",
    "  except:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOUM1SX1p8Yb"
   },
   "source": [
    "首先有\n",
    "$$\n",
    "P(w_n)=\\frac{N(w_n)}{N(words)}\\\\\n",
    "P(w_n|w_{n-1})=\\frac{N(w_{n-1},w_n)}{N(w_{n-1})}\\\\\n",
    "P(w_n|w_{n-2},w_{n-1})=\\frac{N(w_{n-2},w_{n-1},w_n)}{N(w_{n-2},w_{n-1})}\n",
    "$$\n",
    "linear interpolation作业要求没有仔细说，看公式应该是用trigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yn6xIiCmp770"
   },
   "outputs": [],
   "source": [
    "# set lambda\n",
    "lamda = [0.2, 0.4, 0.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4fblZMW54W9"
   },
   "source": [
    "这里有新的问题，就算是用了linear interpolation还是有概率为0的出现，我这里选择将其略过，当然略过是十分不科学的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vGSE3W5vPKY"
   },
   "outputs": [],
   "source": [
    "def cal_pp_linear(words, lamda):\n",
    "  N = len(words)\n",
    "  n_uni = len(unigram)\n",
    "  log_P = 0\n",
    "  for i in range(2, N):\n",
    "    P_uni = uni(words[i])/n_uni\n",
    "    # 如果出现除0错误，一定是分子分母同时为0\n",
    "    try:\n",
    "      P_bi = bi((words[i-1],words[i]))/uni(words[i-1])\n",
    "    except:\n",
    "      P_bi = 0\n",
    "    try:\n",
    "      P_tri = tri((words[i-2],words[i-1],words[i]))/bi((words[i-2],words[i-1]))\n",
    "    except:\n",
    "      P_tri = 0\n",
    "    P_i = P_uni*lamda[2] + P_bi*lamda[1] + P_tri*lamda[0]\n",
    "    \n",
    "    if P_i != 0:  # !!!这里的判断是错的，不应该会有0\n",
    "      log_P += math.log(P_i)\n",
    "  # return (1/math.exp(log_P))**(1/N)\n",
    "  return math.exp(-log_P/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n00_GRY296ZC"
   },
   "source": [
    "Add_lambda模型也没说用哪个，看公式我用了bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-S6MDYB-FDJ"
   },
   "outputs": [],
   "source": [
    "def cal_pp_add(words, lamda):\n",
    "  N = len(words)\n",
    "  V = len(bigram)\n",
    "  log_P = 0\n",
    "  for i in range(1, V):\n",
    "    P = (bi((words[i-1],words[i])) + lamda)/(uni(words[i-1]) + lamda*V)\n",
    "    log_P += math.log(P)\n",
    "  return math.exp(-log_P/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oyRtAzO0ePj"
   },
   "outputs": [],
   "source": [
    "test_words = nltk.word_tokenize(open('testing_data.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2RrGzj8R052Q",
    "outputId": "5277f8e0-657e-439d-e7e9-cd4518fb1179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.40293764580248"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_pp_linear(test_words,lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "A3BSQXjF8H5B",
    "outputId": "3aadbc2b-24c3-4eec-8fd0-799b9da4db43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7677.609728354243\n",
      "8378.780837884206\n",
      "8939.56572198451\n"
     ]
    }
   ],
   "source": [
    "print(cal_pp_add(test_words, 0.1))\n",
    "print(cal_pp_add(test_words, 0.2))\n",
    "print(cal_pp_add(test_words, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ObKecmWAjpk"
   },
   "source": [
    "这样一对比在linear interpolation里扔掉0的做法显然不太靠谱，，但是由于test里出现了train里从来没有的词汇，按我的理解在linear interpolation里他就该是0，我也不知道该怎样处理\n",
    "\n",
    "可能按照说明把test和train里词频低的词都忽略就好了"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nlp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
