{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "LUnLBypJRAyL",
    "outputId": "21381dac-300d-4f9a-87b3-1a1f2d6dbff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "import random\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVIBs4HOedVg"
   },
   "source": [
    "没有做作业要求的文本预处理，但是好像nltk自带了预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTRwquUiRzrt"
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(open('training_data.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdkkSwuGupHR"
   },
   "outputs": [],
   "source": [
    "def set_UNK(words):\n",
    "  count = {}\n",
    "  for word in words:\n",
    "    try:\n",
    "      count[word] += 1\n",
    "    except:\n",
    "      count[word] = 1\n",
    "  for i in range(len(words)):\n",
    "    if count[words[i]]<=3:\n",
    "      words[i] = 'UNK'\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFWNosvbwEyq"
   },
   "outputs": [],
   "source": [
    "tokens = set_UNK(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGfeGOrFe4ef"
   },
   "source": [
    "## build n-grams\n",
    "n-gram都是字典<br/>\n",
    "bigram和trigram的key为了能够写到文件里所以加了一层str()，其实可以去掉，如果不去掉键就是一个str(tuple)，tuple是要查找的键，是一个元组,去掉之后key就是一个元组\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfzDnm7cR6Ln"
   },
   "outputs": [],
   "source": [
    "unigram = {}\n",
    "for token in tokens:\n",
    "  try:\n",
    "    unigram[token] += 1\n",
    "  except:\n",
    "    unigram[token] = 1\n",
    "\n",
    "bigram = {}\n",
    "for i in range(1,len(tokens)):\n",
    "  try:\n",
    "    #bigram[str((tokens[i],tokens[i-1]))] += 1\n",
    "    bigram[(tokens[i],tokens[i-1])] += 1\n",
    "  except:\n",
    "    #bigram[str((tokens[i],tokens[i-1]))] = 1\n",
    "    bigram[(tokens[i],tokens[i-1])] = 1\n",
    "\n",
    "trigram = {}\n",
    "for i in range(2,len(tokens)):\n",
    "  try:\n",
    "    #trigram[str((tokens[i],tokens[i-1],tokens[i-2]))] += 1\n",
    "    trigram[(tokens[i],tokens[i-1],tokens[i-2])] += 1\n",
    "  except:\n",
    "    #trigram[str((tokens[i],tokens[i-1],tokens[i-2]))] = 1\n",
    "    trigram[(tokens[i],tokens[i-1],tokens[i-2])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "mI3Anc59gOqC",
    "outputId": "57bc3cc6-35e1-47df-f75b-dd53e6a64ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34352\n",
      "2475\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "print(unigram['a'])\n",
    "# print(bigram[str(('this','in'))])\n",
    "print(bigram[('this','in')])\n",
    "# print(trigram[str(('as', 'soon', 'as'))])\n",
    "print(trigram[('as', 'soon', 'as')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1rOTPHW1HHq"
   },
   "source": [
    "由于单纯的字典在key不存在时会报错，所以将n_gram封装为函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AnF5L-81RYn"
   },
   "outputs": [],
   "source": [
    "def uni(key):\n",
    "  try:\n",
    "    return unigram[key]\n",
    "  except:\n",
    "    return 0\n",
    "\n",
    "def bi(key):\n",
    "  try:\n",
    "    return bigram[key]\n",
    "  except:\n",
    "    return 0\n",
    "\n",
    "def tri(key):\n",
    "  try:\n",
    "    return trigram[key]\n",
    "  except:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOUM1SX1p8Yb"
   },
   "source": [
    "首先有\n",
    "$$\n",
    "P(w_n)=\\frac{N(w_n)}{N(words)}\\\\\n",
    "P(w_n|w_{n-1})=\\frac{N(w_{n-1},w_n)}{N(w_{n-1})}\\\\\n",
    "P(w_n|w_{n-2},w_{n-1})=\\frac{N(w_{n-2},w_{n-1},w_n)}{N(w_{n-2},w_{n-1})}\n",
    "$$\n",
    "linear interpolation作业要求没有仔细说，看公式应该是用trigram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4fblZMW54W9"
   },
   "source": [
    "这里有新的问题，就算是用了linear interpolation还是有概率为0的出现，我这里选择将其略过，当然略过是十分不科学的，**所以这里其实是不太对的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vGSE3W5vPKY"
   },
   "outputs": [],
   "source": [
    "def cal_pp_linear(words, lamda):\n",
    "  N = len(words)\n",
    "  n_uni = len(unigram)\n",
    "  log_P = 0\n",
    "  for i in range(2, N):\n",
    "    P_uni = uni(words[i])/n_uni\n",
    "    # 如果出现除0错误，一定是分子分母同时为0\n",
    "    try:\n",
    "      P_bi = bi((words[i-1],words[i]))/uni(words[i-1])\n",
    "    except:\n",
    "      P_bi = 0\n",
    "    try:\n",
    "      P_tri = tri((words[i-2],words[i-1],words[i]))/bi((words[i-2],words[i-1]))\n",
    "    except:\n",
    "      P_tri = 0\n",
    "    P_i = P_uni*lamda[2] + P_bi*lamda[1] + P_tri*lamda[0]\n",
    "    \n",
    "    if P_i != 0:  # !!!这里的判断是错的，不应该会有0\n",
    "      log_P += math.log(P_i)\n",
    "  # return (1/math.exp(log_P))**(1/N)\n",
    "  return math.exp(-log_P/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n00_GRY296ZC"
   },
   "source": [
    "Add_lambda模型也没说用哪个，看公式我用了bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-S6MDYB-FDJ"
   },
   "outputs": [],
   "source": [
    "def cal_pp_add(words, lamda):\n",
    "  N = len(words)\n",
    "  V = len(bigram)\n",
    "  log_P = 0\n",
    "  for i in range(1, V):\n",
    "    P = (bi((words[i-1],words[i])) + lamda)/(uni(words[i-1]) + lamda*V)\n",
    "    log_P += math.log(P)\n",
    "  return math.exp(-log_P/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oyRtAzO0ePj"
   },
   "outputs": [],
   "source": [
    "test_words = nltk.word_tokenize(open('testing_data.txt').read())\n",
    "test_words = set_UNK(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yn6xIiCmp770"
   },
   "outputs": [],
   "source": [
    "# set lambdas\n",
    "lamdas = [[0.8, 0.1, 0.1],\n",
    "      [0.6, 0.2, 0.2],\n",
    "      [0.4, 0.3, 0.3],\n",
    "      [0.1, 0.8, 0.1],\n",
    "      [0.2, 0.6, 0.2],\n",
    "      [0.3, 0.4, 0.3],\n",
    "      [0.1, 0.1, 0.8],\n",
    "      [0.2, 0.2, 0.6],\n",
    "      [0.3, 0.3, 0.4],\n",
    "      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6r3blhB4PA4"
   },
   "source": [
    "设置新的训练集和测试集来选择lambda，看着很长，就是抄了一遍上面的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0V1p7tCq3MR5"
   },
   "outputs": [],
   "source": [
    "random.shuffle(test_words)\n",
    "n = int(0.8*len(test_words))\n",
    "new_training = test_words[:n]\n",
    "held_out = test_words[n:]\n",
    "\n",
    "new_unigram = {}\n",
    "for word in new_training:\n",
    "  try:\n",
    "    new_unigram[word] += 1\n",
    "  except:\n",
    "    new_unigram[word] = 1\n",
    "\n",
    "new_bigram = {}\n",
    "for i in range(1,len(new_training)):\n",
    "  try:\n",
    "    new_bigram[(new_training[i],new_training[i-1])] += 1\n",
    "  except:\n",
    "    new_bigram[(new_training[i],new_training[i-1])] = 1\n",
    "\n",
    "new_trigram = {}\n",
    "for i in range(2,len(new_training)):\n",
    "  try:\n",
    "    new_trigram[(new_training[i],new_training[i-1],new_training[i-2])] += 1\n",
    "  except:\n",
    "    new_trigram[(new_training[i],new_training[i-1],new_training[i-2])] = 1\n",
    "\n",
    "def new_uni(key):\n",
    "  try:\n",
    "    return new_unigram[key]\n",
    "  except:\n",
    "    return 0\n",
    "\n",
    "def new_bi(key):\n",
    "  try:\n",
    "    return new_bigram[key]\n",
    "  except:\n",
    "    return 0\n",
    "\n",
    "def new_tri(key):\n",
    "  try:\n",
    "    return new_trigram[key]\n",
    "  except:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "HX1JAn532DZK",
    "outputId": "abe6c85e-df62-4f14-a749-8ab98574dd04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda: [0.8, 0.1, 0.1] perplexity: 76\n",
      "lambda: [0.6, 0.2, 0.2] perplexity: 38\n",
      "lambda: [0.4, 0.3, 0.3] perplexity: 26\n",
      "lambda: [0.1, 0.8, 0.1] perplexity: 72\n",
      "lambda: [0.2, 0.6, 0.2] perplexity: 38\n",
      "lambda: [0.3, 0.4, 0.3] perplexity: 26\n",
      "lambda: [0.1, 0.1, 0.8] perplexity: 10\n",
      "lambda: [0.2, 0.2, 0.6] perplexity: 13\n",
      "lambda: [0.3, 0.3, 0.4] perplexity: 19\n"
     ]
    }
   ],
   "source": [
    "# 这里pp_new和上面的linear一样\n",
    "def pp_new(words, lamda):\n",
    "  N = len(words)\n",
    "  n_uni = len(new_unigram)\n",
    "  log_P = 0\n",
    "  for i in range(2, N):\n",
    "    P_uni = new_uni(words[i])/n_uni\n",
    "    try:\n",
    "      P_bi = new_bi((words[i-1],words[i]))/new_uni(words[i-1])\n",
    "    except:\n",
    "      P_bi = 0\n",
    "    try:\n",
    "      P_tri = new_tri((words[i-2],words[i-1],words[i]))/new_bi((words[i-2],words[i-1]))\n",
    "    except:\n",
    "      P_tri = 0\n",
    "    P_i = P_uni*lamda[2] + P_bi*lamda[1] + P_tri*lamda[0]\n",
    "    \n",
    "    if P_i != 0:\n",
    "      log_P += math.log(P_i)\n",
    "  return math.exp(-log_P/N)\n",
    "\n",
    "# search best lambda\n",
    "best_lamda = lamdas[0]\n",
    "min_pp = float('inf')\n",
    "for lamda in lamdas:\n",
    "  p = pp_new(held_out, lamda)\n",
    "  print('lambda: %s perplexity: %d'%(str(lamda),p))\n",
    "  if p < min_pp:\n",
    "    min_pp = p\n",
    "    best_lamda = lamda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "LPmCMfSS7YIE",
    "outputId": "6c457956-bf8c-4f32-df06-d4970caa5235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.1, 0.8]\n",
      "10.0114975138329\n"
     ]
    }
   ],
   "source": [
    "print(best_lamda)\n",
    "print(min_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_RYcc_721DO"
   },
   "source": [
    "## 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2RrGzj8R052Q",
    "outputId": "3ac84af8-3647-4f3c-c7d8-e35fb8e117f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0184564063546855"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_pp_linear(test_words,best_lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "A3BSQXjF8H5B",
    "outputId": "c63fa03f-94ee-4326-ae88-217b00a30ef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1322.6583518470272\n",
      "1496.918083318506\n",
      "1631.312551518584\n"
     ]
    }
   ],
   "source": [
    "print(cal_pp_add(test_words, 0.1))\n",
    "print(cal_pp_add(test_words, 0.2))\n",
    "print(cal_pp_add(test_words, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ObKecmWAjpk"
   },
   "source": [
    "这样一对比在linear interpolation里扔掉0的做法显然不太靠谱，，但是由于test里出现了train里从来没有的词汇，按我的理解在linear interpolation里他就该是0，我也不知道该怎样处理\n",
    "\n",
    "可能按照说明把test和train里词频低的词都忽略就好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zbsbzxvi_LL5"
   },
   "outputs": [],
   "source": [
    "# 第一问的保存计数\n",
    "unigram = {}\n",
    "for token in tokens:\n",
    "  try:\n",
    "    unigram[token] += 1\n",
    "  except:\n",
    "    unigram[token] = 1\n",
    "\n",
    "bigram = {}\n",
    "for i in range(1,len(tokens)):\n",
    "  try:\n",
    "    bigram[str((tokens[i],tokens[i-1]))] += 1\n",
    "    # bigram[(tokens[i],tokens[i-1])] += 1\n",
    "  except:\n",
    "    bigram[str((tokens[i],tokens[i-1]))] = 1\n",
    "    # bigram[(tokens[i],tokens[i-1])] = 1\n",
    "\n",
    "trigram = {}\n",
    "for i in range(2,len(tokens)):\n",
    "  try:\n",
    "    trigram[str((tokens[i],tokens[i-1],tokens[i-2]))] += 1\n",
    "    # trigram[(tokens[i],tokens[i-1],tokens[i-2])] += 1\n",
    "  except:\n",
    "    trigram[str((tokens[i],tokens[i-1],tokens[i-2]))] = 1\n",
    "    # trigram[(tokens[i],tokens[i-1],tokens[i-2])] = 1\n",
    "\n",
    "import json\n",
    "with open('unigram.txt','w') as f:\n",
    "  f.write(json.dumps(unigram))\n",
    "with open('bigram.txt','w') as f:\n",
    "  f.write(json.dumps(bigram))\n",
    "with open('trigram.txt','w') as f:\n",
    "  f.write(json.dumps(trigram))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nlp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
